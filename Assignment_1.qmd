---
title: "Fundamentals of R: Assignment 1"
author: "Marisca Westerhof (0706116), Matias Edelstein (1296337), Sjors Wilkes (6377130)"
date: "12/08/2025"
format: html
toc: true
---
## Introduction

As a cornerstone of our financial systems, the ability to receive a loan is essential to the livelihood of many families, entrepreneurial ventures, and big business alike. However, to minimize the chance of default creditors establish stringent criteria for loan approval; each case is evaluated depending on multiple factors. Since most individuals in their lives are likely to loan money, we find this topic to be highly relevant. For this research, we have chosen a dataset of loan approval in the US and Canada. From this, we hope to build a model that can accurately predict the loan amount an individual will receive if they apply for a loan based on various factors. Hence, our research aims to answer the question: Do payment to income ratio, annual income, product type, years employed, age, loan status, defaults on file, credit score, derogatory marks, delinquencies last 2 years, debt to income ratio, loan to income ratio, interest rate, and occupation status have a causal effect on the loan amount applicants receive in the US and Canada? The significance level we will use for the F-test of each model is 0.05. 

Our dataset was retrieved from: [Kaggle](https://www.kaggle.com/datasets/parthpatel2130/realistic-loan-approval-dataset-us-and-canada?resource=download)

## Part 1: Coming up with the RQ
### Step 1.0: Preliminary Setting Up
```{r 0.0, message=FALSE, warning=FALSE, error=FALSE}
library(tidyverse)
library(plotly)
library(gridExtra)
library(corrplot)
library(ggplot2)
library(reshape2)
library(modelr)
library(car)
library(kableExtra)

# preliminary observation of the data to see which how many variables there are and their respective data types
df <- read.csv("../Data/Loan_approval_data_2025.csv")
tibble(head(df))
str(df)
```
In total, our data sest has 50,000 data points, which have been measured across 20 different variables.

### Step 1.1: Pre-processing
```{r 0.1}

# checking for missing values, to see if data cleaning is necessary 
check_missing_values <- is.na.data.frame(df)
total_missing_values <- sum(check_missing_values) 

print(total_missing_values)
```
From our pre-processing step, we can see that there are no missing values. This means that we will not have to engage in further data cleaning methods.

### Step 1.2: Statistic Summary Table
To better understand the variables we are working with, we have decided to make a summary (statistic) table. However, since categorical variables don't have summary statistics, we are making two seperate tables. 

#### Step 1.2.1: Statistic Summary Table for Numerical Variables
```{r}

# cleaning the data for numerical variables as the pearson correlation matrix is only suited to numerical data

df_numerical_data_only <- df %>%
  select(-customer_id,-occupation_status,-product_type,-loan_intent,)

# summary statistics in table, for easy visibility
summary_stats_num <- tibble(
  Variable = colnames(df_numerical_data_only),
  Min = sapply(df_numerical_data_only, min),
  Mean = sapply(df_numerical_data_only, mean),
  Max = sapply(df_numerical_data_only, max),
  IQR = sapply(df_numerical_data_only, IQR),
  Description = c("Age of applicant (years)",
    "Years employed by applicant",
    "Annual income ($)",
    "Credit score",
    "Credit history in years",
    "Savings / assets ($)",
    "Current debt ($)",
    "Defaults on file (count)",
    "Delinquencies in last 2 years (count)",
    "Derogatory marks (count)",
    "Loan amount ($)",
    "Interest rate (%)",
    "Debt-to-income ratio",
    "Loan-to-income ratio",
    "Payment-to-income ratio",
    "Loan status (0 = no, 1 = yes)"
  )
)

# cleaning up the table for easy visibility
summary_stats_rounded <- summary_stats_num %>% 
  mutate(across(c(Mean, Max, IQR), ~round(.,2)))

kable(summary_stats_rounded, align = c('l','c','c','c','c','r')) %>% 
  kable_styling(bootstrap_options = 'striped','hover')
```
#### Step 1.2.2: Summary Table for Categorical Variables
```{r}

# what are the possible categorical variables in 
unique(df$occupation_status)
unique(df$product_type)
unique(df$loan_intent)

# creating a df for categorical variables to as easy reference point
summary_cat <- as.data.frame(list(
  Variable = c("occupation_status", "product_type", "loan_intent"),
  Categories = c(
    "Employed, Student, Self-Employed",
    "Credit Card, Personal Loan, Line of Credit",
    "Business, Home Improvement, Debt Consolidation, Education, Personal, Medical"
  ),
  Description = c(
    "Employment status of the applicant",
    "Type of loan product requested",
    "Purpose of the loan"
  )
))

kable(summary_cat) %>%
  kable_styling(full_width = TRUE)

```

### Step 1.3: Variable Visualization

To further understand our data better, we visualized all of our variables. For this, histograms are used for numerical variables, while bar charts for categorical variables. 

#### 1.3.1: Histograms for Numerical Variables
```{r 0.2_numerical, warning=FALSE}
par(mfrow = c(2, 5))


# general theme histogram 
theme_histo <- theme_minimal(base_size = 9) + 
  theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 7),
axis.title.y = element_blank(),
axis.text.x = element_text(size = 7),
axis.text.y = element_text(size = 7),
plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
plot.margin = margin(2, 2, 2, 2, unit = "pt")
)

# age
p1 <- ggplot(df) + geom_histogram(aes(x = age), binwidth = 1) +theme_histo 

# filter out cases younger than 18
# df <- df %>% filter(age > 17)

# years_employed

p2 <- ggplot(df) + geom_histogram(aes(x = years_employed), binwidth = 1)+theme_histo 

# annual_income

p3 <- ggplot(df) + geom_histogram(aes(x = annual_income), bins = 50)+ 
  theme_histo 

# credit_score

p4 <- ggplot(df) + geom_histogram(aes(x = credit_score), bins = 50)+
  theme_histo 
# credit_history_years

p5 <- ggplot(df) + geom_histogram(aes(x = credit_history_years), binwidth = 1)+
  theme_histo 

#savings_assets: in order to show the distribution clearly, we've transformed the x-axis to a logarithmic scale

p6 <- ggplot(df) +
  geom_histogram(aes(x = log10(savings_assets)), bins = 50) +
  scale_x_continuous(
    breaks = log10(c(10, 100, 1000, 10000, 100000)),
    labels = c(10, 100, 1000, 10000, 100000)
  ) +
  theme_histo 

#current_debt - 

p7 <- ggplot(df) + geom_histogram(aes(x = current_debt), bins = 50) +
  theme_histo 


#delinquencies_last_2yrs 

p8 <- ggplot(df) + geom_histogram(aes(x = delinquencies_last_2yrs), binwidth = 0.5) +theme_histo 

#derogatory_marks

p9 <- ggplot(df) + geom_histogram(aes(x = derogatory_marks), binwidth = 0.5) +theme_histo 

#loan_amount 

p10 <- ggplot(df) + geom_histogram(aes(x = loan_amount), bins=50) +theme_histo 

#interest_rate

p11 <- ggplot(df) + geom_histogram(aes(x = interest_rate), bins = 50) +theme_histo 

#debt_to_income_ratio

p12 <- ggplot(df) + geom_histogram(aes(x = debt_to_income_ratio), binwidth = 0.01) +theme_histo 


#loan_to_income_ratio 

p13 <- ggplot(df) + geom_histogram(aes(x = loan_to_income_ratio), binwidth = 0.01) +theme_histo 

#payment_to_income_ratio --

p14 <- ggplot(df) + geom_histogram(aes(x = payment_to_income_ratio), binwidth = 0.01) +theme_histo 

#arrangement numerical plots

grid.arrange(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11,p12,p13,p14, ncol = 4)

```
An interesting observation we can make for our target variable, loan amount (which is how much an individual is loaned by a bank) has a frequency that is steadily decreasing as loans get bigger. However, there are spikes at the loan amount of 70000 dollars and 100000 dollars, which goes against the observed pattern. A less noticeable but yet interesting pattern is also the spike at 50000 dollar loans. This could be for numerous reasons, such as the fact that banks loan in fixed "packages", or that these are the maximum loans for various wealth groups. Either way, this is important to note for our regression, as this will have implications for the fit of the model.  

#### 1.3.2: Bar Plots for Categorical Data
```{r 0.2_categorical}

#general theme barplot
theme_barplot <-  theme_bw(base_size = 9) + 
  theme(panel.grid.major = element_blank(),
panel.grid.minor = element_blank(),
axis.title.x = element_text(size = 7),
axis.title.y = element_blank(),
axis.text.x = element_text(size = 7, angle = 45, hjust = 1),
axis.text.y = element_text(size = 7),
plot.title = element_text(size = 9, face = "bold", hjust = 0.5),
plot.margin = margin(2, 2, 10, 2, unit = "pt"),
aspect.ratio = 0.8,
legend.key.size = unit(0.3, "cm")
)

# occupation status

df$occupation_status <- factor(df$occupation_status)

b1 <- ggplot(df, aes(x = occupation_status, fill = occupation_status)) +
  geom_bar() + 
  theme_barplot


# product type
df$product_type <- factor(df$product_type)

b2 <- ggplot(df, aes(x = product_type, fill = product_type)) +
  geom_bar() +
  theme_barplot


# loan intent: change the categorical variable into a factor 
df$loan_intent <- factor(df$loan_intent)

b3 <- ggplot(df, aes(x = loan_intent, fill = loan_intent)) +
  geom_bar() + 
  theme_barplot

# defaults_on_file 

b4 <- ggplot(df, aes(x = factor(defaults_on_file, levels = c(0,1), labels = c("no", "yes")),
                     fill = factor(defaults_on_file))) +
  geom_bar() +
  labs(x = "defaults_on_file", fill = "Defaults") +
  theme_barplot

# loan_status 

b5 <- ggplot(df, aes(x = factor(loan_status, levels = c(0,1), labels = c("no", "yes")),
                     fill = factor(loan_status))) +
  geom_bar() +
  labs(x = "Loan Status", fill = "Loan Status") +
  theme_barplot


grid.arrange(b1,b2,b3,b4, b5, ncol = 3)
```

### Step 1.3: Making a Pearson Correlation Matrix
Inspiration for the correlation matrix visualization: https://www.datacamp.com/tutorial/variance-inflation-factor 
```{r 0.3}
# using the data frame with only numerical data points used from the previous section

correlation_matrix_numerical <- cor(df_numerical_data_only)

# plotting the correlation plot to better understand how the variables correlate with loan_amount

melted_corr_matrix_numerical <- melt(correlation_matrix_numerical)

corr_plot <- ggplot(data = melted_corr_matrix_numerical, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                       midpoint = 0, limit = c(-1, 1), space = "Lab", 
                       name="Correlation") +
  theme_minimal() + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1)) +
  labs(x = "", y = "") + 
  geom_text(aes(Var1, Var2, label = round(value, 2)), color = "black", size = 2) +
  theme(axis.text=element_text(size=10))

corr_plot
```

## Part 2: Model Estimation
In order to determine which variables would have the highest potential as predictors of loan amount, we looked at the correlation matrix that we made in the previous section as our baseline for our model. From there, we added both numerical and categorical predictors to subsequent model iterations.

### Step 2.1 Making linear regression models, using with high levels of correlation with loan amount as our starting point

#### Model 1: Payment to Income Ratio

We started out with testing payment_to_income_ratio as a predictor of loan amount, as it has a correlation of 0.66. 
```{r 2.1_model_1}

# building model1
model1 <- lm(loan_amount ~ payment_to_income_ratio, data = df)
summary(model1)

# making predictor model
model1_pred <- df %>%
  add_predictions(model1) %>% 
  rename(predicted_loan_amount = pred)

# drawing a random sample of model1_pred to avoid overcrowding the visualization
set.seed(123)
model1_pred_sampled <- model1_pred %>% 
  sample_n(500)

# plotting the regression with the sample
model1_plot <- model1_pred_sampled %>%
  ggplot(aes(loan_amount, predicted_loan_amount)) +
  geom_point() +
  geom_segment(aes(xend = loan_amount, yend = loan_amount), col = "red") +
  geom_smooth(method = "lm", col = "blue")
ggplotly(model1_plot)
```
Model 1 demonstrates that Payment to Income Ratio is a highly significant predictor for loan amount, with a coefficient of 111378.4. This means that for each 1 percentage point increase in the payment-to-income ratio, the predicted loan amount increases by 111378.4 dollars. The r-squared value = is 0.4385, which signals a large effect. Still, as Model 1 is a simple linear regression, we can get more accurate results by using a multiple linear regression. 

#### Model 2: Payment to Income Ratio and Annual Income

Model 2 builds on the first model, this time adding annual income as the second predictor of loan amount. The reason we opted for this as our second predictor is because it has a correlation of 0.51 with loan amount. 
```{r 2.1_model_2}
# building model 2
model2 <- lm(loan_amount ~ payment_to_income_ratio + annual_income, data = df)
summary(model2)

# making predictor model
model2_pred <- df %>%
  add_predictions(model2) %>% 
  rename(predicted_loan_amount = pred)

# drawing a random sample of model2_pred to avoid overcrowding the visualization
model2_pred_sampled <- model2_pred %>% 
  sample_n(500)

# plotting the regression with the sample
model2_plot <- model2_pred_sampled %>%
  ggplot(aes(loan_amount, predicted_loan_amount)) +
  geom_point() +
  geom_segment(aes(xend = loan_amount, yend = loan_amount), col = "red") +
  geom_smooth(method = "lm", col = "blue")
ggplotly(model2_plot)
```
Comparing model 2 to model 1, we see a substantial improvement in model fit, as the R-squared increased to 0.8088. The overall F-test for model 2 is highly statistically significant, indicating that the predictors collectively explain a meaningful amount of variation in loan amount. The coefficient for payment to income ratio also increased compared to model 1, indicating a stronger predicted effect on loan amount. Annual_income is statistically significant as well, although its coefficient is relatively small (0.4918 per dollar). However, we anticipate potential multicollinearity issues because annual_income and payment_to_income_ratio are likely highly correlated, which could make the individual coefficients less reliable. This will be checked in the next section. 

#### Model 3,4,5: Adding More Predictors

Additional predictors were added to the models to observe how the r-squared value and model fit changed. For each model, we checked the F-test to ensure that the predictors collectively had a statistically significant effect on loan amount.

#### Model 3

```{r 2.1_model_3}

# model 3: adding product type, years employed, age, loan status, defaults on file, loan intent, and credit score as predictors
model3 <- lm(loan_amount ~ payment_to_income_ratio + annual_income + product_type + years_employed + age + loan_status + defaults_on_file + loan_intent + credit_score, data = df)
summary(model3)

# making predictor model
model3_pred <- df %>%
  add_predictions(model3) %>% 
  rename(predicted_loan_amount = pred)

# 1.3: drawing a random sample of model3_pred to avoid overcrowding the visualization
model3_pred_sampled <- model3_pred %>% 
  sample_n(500)

# 1.4: plotting the regression with the sample
model3_plot <- model3_pred_sampled %>%
  ggplot(aes(loan_amount, predicted_loan_amount)) +
  geom_point() +
  geom_segment(aes(xend = loan_amount, yend = loan_amount), col = "red") +
  geom_smooth(method = "lm", col = "blue")
ggplotly(model3_plot)
```
In Model 3, we can see that model fit has only slightly increased to R-squared = 0.8117. The coefficient for payment-to-income ratio decreased slightly, meaning that a 1 percentage point increase in the ratio is associated with an increase in loan amount of approximately 124,000 dollars. Conversely, annual income decreased slightly, meaning that for each additional dollar of annual income, the loan amount increases by about 0.48 dollars. 

Product type was found to be a significant predictor. Interestingly, if your product type is a Line of Credit, this decreases your loan amount by approximately 1,864 dollars. However, if your product type is a Personal Loan, the loan amount increases by about 689 dollars.

Age and loan status were also found to be highly significant. Years employed, defaults on file, and credit score were significant at the 0.01 level, which is still below our assigned significance threshold. Interestingly, loan intent does not have an impact on the loan amount that is granted, which means that it will be removed as a predictor in model 4. 

#### Model 4
```{r 2.1_model_4}

# model 4: adding derogatory marks, delinquencies last 2yrs, debt to income ratio, loan to income_ratio, interest rate and occupation status onto model3;
# removing loan intent as it was not seen to be significant in the previous model

model4 <- lm(loan_amount ~ payment_to_income_ratio + annual_income + product_type + years_employed + age + loan_status + defaults_on_file + credit_score + derogatory_marks + delinquencies_last_2yrs + debt_to_income_ratio + loan_to_income_ratio + interest_rate + occupation_status, data = df)
summary(model4)

# making predictor model
model4_pred <- df %>%
  add_predictions(model4) %>% 
  rename(predicted_loan_amount = pred)

# drawing a random sample of model4_pred to avoid overcrowding the visualization
model4_pred_sampled <- model4_pred %>% 
  sample_n(500)

# plotting the regression with the sample
model4_plot <- model4_pred_sampled %>%
  ggplot(aes(loan_amount, predicted_loan_amount)) +
  geom_point() +
  geom_segment(aes(xend = loan_amount, yend = loan_amount), col = "red") +
  geom_smooth(method = "lm", col = "blue")
ggplotly(model4_plot)
```
In Model 4, the overall model fit shows only a very slight increase compared to Model 3, with r-squared = 0.8119. Notably, the coefficient for payment-to-income ratio is very small and no longer statistically significant, suggesting that once similar income-related predictors such as debt-to-income ratio and loan-to-income ratio are included, the effect of payment-to-income ratio is largely absorbed by these new predictors. Hence, it will not be included in Model 5. 

Product type continues to influence loan amount, with a Line of Credit reducing the loan by approximately 1,929 dollars and a Personal Loan showing a smaller, marginal increase of about 624 dollars, which is only weakly significant.
 
Among the newly added predictors, delinquencies in the last 2 years, debt-to-income ratio, and occupation status - particularly self-employed borrowers - are significant. For self-employed individuals, their loan amount increases by 732.8 dollars versus those who are not. However, loan-to-income ratio, interest rate, and credit score, are not significant in this model, so they will also not be included in Model 5. Years employed, age, and loan status remain important predictors, consistent with Model 3.
The overall F-test remains highly significant.
```{r 2.1_model_5}
# model 5: building on model 4, removing payment to income ratio, loan to income ratio, interest rate, and credit score as these predictors were not seen to be significant

model5 <- lm(loan_amount ~ annual_income + product_type + years_employed + age + loan_status + defaults_on_file + derogatory_marks + delinquencies_last_2yrs + debt_to_income_ratio + occupation_status, data = df)
summary(model5)

# making predictor model
model5_pred <- df %>%
  add_predictions(model5) %>% 
  rename(predicted_loan_amount = pred)

# drawing a random sample of model4_pred to avoid overcrowding the visualization
model5_pred_sampled <- model5_pred %>% 
  sample_n(500)

# plotting the regression with the sample
model5_plot <- model5_pred_sampled %>%
  ggplot(aes(loan_amount, predicted_loan_amount)) +
  geom_point() +
  geom_segment(aes(xend = loan_amount, yend = loan_amount), col = "red") +
  geom_smooth(method = "lm", col = "blue")
ggplotly(model5_plot)

```

In Model 5, all predictors are seen to be statistically significant; however, the R-squared value has almost halved to 0.4042, which is highly unexpected. This likely occurs because, even though the predictors are individually significant, removing key income-related variables such as payment-to-income ratio reduces the model’s ability to explain overall variation in loan amounts.

Looking at the coefficients, annual income, years employed, age, and loan status continue to have strong, expected effects on loan amount. Product type also remains influential, but the direction of effects differs: a line of credit now reduces loan amount by about 8,017 dollars, while a personal loan increases it by approximately 13,920 dollars, both highly significant.

Interestingly, some variables that were weak or non-significant in Model 4, such as defaults on file, derogatory marks, delinquencies in the last 2 years, debt-to-income ratio, and occupation status, now show strong statistical significance. For example, being self-employed increases the loan amount by about 865 dollars, whereas students show a large negative effect of around 12,110 dollars.

### Step 2.2 Comparing the Various Models  
```{r AIC_BIC_MSE_scores}
# anova to compare the 
anova(model1,model2,model3,model4,model5)

# evaluating how model1 and model2 compare on AIC, BIC, MSE, and ANOVA metrics
AICscores <- rbind(AIC(model1),AIC(model2),AIC(model3),AIC(model4),AIC(model5)) 

# BIC: which model predicts the simplest
BICscores <- rbind(BIC(model1),BIC(model2),BIC(model3),BIC(model4),BIC(model5)) 

# mean squares 
MSEscores <- rbind(mean(model1$residuals)^2, mean(model2$residuals)^2,mean(model3$residuals)^2, mean(model4$residuals)^2, mean(model5$residuals)^2)

# r-squared scores: explained variance
Rsquared <- rbind(summary(model1)$r.squared,
                  summary(model2)$r.squared,
                  summary(model3)$r.squared,
                  summary(model4)$r.squared,
                  summary(model5)$r.squared)

# making a table that compares model 1 and model 2
score_eval <- cbind(AICscores, BICscores, MSEscores, Rsquared)
rownames(score_eval) <- c("model1", "model2", "model3", "model4", "model5")
colnames(score_eval) <- c("AIC", "BIC", "MSE", "R-squared")

score_eval_df <- as.data.frame(score_eval)
score_eval_df
```
Based on the comparison of the five models using AIC, BIC, and MSE, Model 4 emerges as the best overall choice. It has the lowest AIC (1,075,418) and BIC (1,075,577), indicating that it achieves the best balance between model fit and complexity. Its R-squared of 0.8119 is also the highest of all the models. While Model 5 has the smallest MSE, its AIC (1133057) and BIC (1133180) are the highest of the 5 models- even higher than the simple linear regression, and explaining much less of the data with an R-squared value of 0.4020- making it the lowest of all the models.

While Model 4 did not have one of the lowest MSE's, all of the models had extremely low MSE values so there is not much of a difference there. Models 1 and 2 are clearly inferior, with much higher AIC and BIC values, and Model 3 is slightly behind Model 4 in both information criteria. Overall, Model 4 provides a good of predictive accuracy and simplicity, making it the preferred model for this data.

This is probably due to the fact that Model 4 has the most predictors present compared to all of the models. However, as we saw that some predictors were not considered to be significant at the 5% level. Since our focus is on the overall significance and explanatory power of the model rather than on the significance of individual predictors, it is acceptable to retain variables that are not statistically significant on their own. Furthermore, because both AIC and BIC penalize the loss of model fit more than they reward the reduction in complexity, this indicates that the removed variables still contributed to explaining variation in the response. To address this issue, we will use the assumptions in the next section as a means of feature selection to test which predictors should be dropped for our final model. 

### Step 2.3 Moderator Model 

In this moderator model, we focus on annual income and occupation status because the effect of income on loan amount is likely influenced by the type of occupation. Borrowers with different occupation statuses may have varying levels of financial stability and borrowing patterns. There are three types of occupation statuses: employed, self-employed, or student. This plays into why, we chose occupation status specifically because in Model 4, self-employed individuals get loans are around 732 dollars higher, and students get a loan that is around 326 higher. By including occupation_status as a moderator, we can examine whether the relationship between income and loan amount differs across these groups, providing a more nuanced understanding of how income translates into borrowing capacity.

```{r 2.3.1}
# building the moderator model

model4_mod <- lm(loan_amount ~ annual_income * occupation_status, data = df)

summary(model4_mod)
```
The moderator model shows that occupation status changes how income affects loan amount. Self-employed borrowers get much higher loans than in model 4: 11,450 dollars more. However, the effect of income is smaller for them, while the interaction for students is not significant. Overall, income still matters, but occupation unsurprisingly moderates this relationship, and the model explains about 0.29 percent of the variation, which is a lot less than model 4.

```{r 2.3.2}
# comparing the moderator model to our chosen model 

anova(model4,model4_mod)

# evaluating how model1 and model2 compare on AIC, BIC, MSE, and ANOVA metrics
AICscores_mod <- rbind(AIC(model4),AIC(model4_mod)) 

# which model predicts the simplest
BICscores_mod <- rbind(BIC(model4),BIC(model4_mod)) 

# mean squares 
MSEscores_mod <- rbind(mean(model4$residuals)^2, mean(model4_mod$residuals)^2)

# r-squared scores: explained variance
Rsquared_mod <- rbind(summary(model4)$r.squared,
                  summary(model4_mod)$r.squared)

# making a table that compares model 4 and the moderator model
score_eval_mod <- cbind(AICscores_mod, BICscores_mod, MSEscores_mod, Rsquared_mod)
rownames(score_eval_mod) <- c("model4", "model4_mod")
colnames(score_eval_mod) <- c("AIC", "BIC", "MSE", "R-squared")

score_eval_df_mod <- as.data.frame(score_eval_mod)
score_eval_df_mod
```
Comparing Model 4 and the moderator model, we see that the moderator model has much higher AIC and BIC values, suggesting a worse overall fit. As previously mentioned, R-squared drops from 0.81 in Model 4 to 0.29 in the moderator model, indicating that much less of the variation in loan amount is explained. While the MSE is slightly lower, Model 4 still remains superior. 

## Part 3: Checking Assumptions of the Regression Model

### Assumption 1: No Multicollinearity - Pearson Correlation Matrix for Numerical Data
```{r 3.1}

# to see which predictors have high multicollinearity, vif scores are checked to see if they are less than 10
model4_vif <- model4 %>%
  vif()
print(model4_vif)

# bringing back the correlation matrix to see which associations are specifically causing high multicollinearity
corr_plot

# see what the vif scores would look like without loan to income ratio
model4_v1 <- lm(loan_amount ~ payment_to_income_ratio + annual_income + product_type + years_employed + age + loan_status + defaults_on_file + credit_score + derogatory_marks + delinquencies_last_2yrs + debt_to_income_ratio + interest_rate + occupation_status, data = df)

model4_v1_vif <- model4_v1 %>%
  vif()
print(model4_v1_vif)
```
Overall, the model exhibits very little multicollinearity, with one clear exception: the payment-to-income ratio and loan-to-income ratio. The VIF for this pair is extremely high (570), which is unsurprising. Looking at the correlation plot, these two variables have a correlation of 1, indicating a virtually perfect linear relationship. This clearly suggests that one of the two should be removed to avoid redundancy.

To address this, we dropped loan-to-income ratio when building Model 4, Version 1. After this adjustment, all VIF values for the remaining predictors are below 10, satisfying the common threshold for acceptable multicollinearity. While interest rate still shows moderate multicollinearity, its VIF is below 10, so it is not considered problematic.

### Assumption 2: Linearity Between Independent Variables and Dependent Variable
As not all predictors are numerical, only numerical variables will be checked for linearity with loan amount.
```{r 3.2.1, warnings=FALSE}


# drawing a random sample of the df to avoid overcrowding the visualization
df_sampled <- df %>% 
  sample_n(1000)

# linearity payment_to_income_ratio
viz_payment_to_income_ratio <- df_sampled %>% 
  ggplot(aes(x = payment_to_income_ratio, y = loan_amount)) +
  geom_point() +
  geom_smooth()

# linearity annual_income
viz_annual_income <- df_sampled %>%
  ggplot(aes(x = annual_income, y = loan_amount)) +
  geom_point() +
  geom_smooth()

# linearity years_employed
viz_years_employed <- df_sampled %>%
  ggplot(aes(x = years_employed, y = loan_amount)) +
  geom_point() +
  geom_smooth()

# linearity age
viz_age <- df_sampled %>%
  ggplot(aes(x = age, y = loan_amount)) +
  geom_point() +
  geom_smooth()

# linearity credit_score
viz_credit_score <- df_sampled %>%
  ggplot(aes(x = credit_score, y = loan_amount)) +
  geom_point() +
  geom_smooth()

# linearity debt_to_income_ratio
viz_debt_to_income_ratio <- df_sampled %>%
  ggplot(aes(x = debt_to_income_ratio, y = loan_amount)) +
  geom_point() +
  geom_smooth()

# linearity interest_rate
viz_interest_rate <- df_sampled %>%
  ggplot(aes(x = interest_rate, y = loan_amount)) +
  geom_point() +
  geom_smooth()

grid.arrange(
  viz_payment_to_income_ratio,
  viz_annual_income,
  viz_years_employed,
  viz_age,
  viz_credit_score,
  viz_debt_to_income_ratio,
  viz_interest_rate,
  ncol = 2
)

```

When examining the linearity between each independent variable and loan amount, payment to income ratio shows the most linear relationship, which makes sense given its high correlation of 0.66. Annual income starts roughly linear but tapers off after about 70,000 dollars, clearly violating linearity. Years employed is also non-linear, as it demonstrates a slight curvature in the shape of a horizontal "s". Age is mostly flat with a slight curve in the middle, showing only a minor departure from linearity. Credit score and debt-to-income ratio are fairly linear, with gentle positive and negative slopes, respectively. Interest rate, however, displays a curved pattern, violating the linearity assumption. Overall, linearity is clearly violated for annual income, years employed, and interest rate, while the other variables generally satisfy the assumption.

```{r 3.1.1}
model4_v2 <- lm(loan_amount ~ payment_to_income_ratio + product_type + age + loan_status + defaults_on_file + credit_score + derogatory_marks + delinquencies_last_2yrs + debt_to_income_ratio + occupation_status, data = df)
summary(model4_v1)
summary(model4_v2)
```
Removing the predictors that violate linearity (annual income, years employed, and interest rate) in model4_v2 leads to a substantial drop in R-squared from 0.8118 to 0.5366, showing that these variables explain a large portion of the variance in loan amount. The residual standard error also increases from 11,330 to 17,780, indicating a poorer fit without them. This comparison highlights a trade-off: removing predictors that violate linearity fulfill the assumptions, however, explained variance goes down substantially- suggesting that binning or taking the square root of some of these predictors might be the way to go. Because these variables are important for explaining loan amount despite their nonlinearity, we continue with model 4 version 1 to preserve predictive power and overall model performance.

### Assumption 3: Exogeniety
Exogeneity questions whether the independent variables are correlated with the errors. This assumption is the most difficult to prove strictly because exhaustive data would be required.

One way to evaluate this is to approach it using theoretical justification. We can ask, "could the error term (unmeasured variables) cause changes in X?"

Our best model currently uses the following independent variables:

```{r}
# | echo: false

model4_vars <- matrix(
  c('payment_to_income_ratio', 'annual_income', 'product_type', 'years_employed', 'age', 'loan_status', 'defaults_on_file', 'credit_score', 'derogatory_marks', 'delinquencies_last_2yrs', 'debt_to_income_ratio', 'loan_to_income_ratio', 'interest_rate', 'occupation_status'),
  ncol = 2,
  byrow = TRUE)

kable(model4_vars) %>% 
  kable_styling(bootstrap_options = 'striped')

```

#### Education Level and Field of Study

Education is not captured by our model but may be associated with several of the independent variables, such as: occupation status, years employed, credit score, and annual income. For example, we would assume that a highly educated individual would have a higher income and more likely to be employed.

#### Health, Major Life Events and Delinquencies

Health crises and other major life events, such as being in an area geographically prone to natural disasters, likely have a relationship with loan delinquency in the last 2 years. However, we do not include these factors in our model. In future iterations, including health data and geography would be helpful in improving our model.

#### Feedback Effects

The biggest challenge to exogeneity are the feedback effects. The data represents these individuals in a static moment in time when in fact there is a story. An individual may have had a loan denied which in turn influenced their credit score. Or, a bank may have restricted credit access which then influenced another one of the variables above, such as delinquency.

For the exogeneity assumption to be held true, we are assuming that our independent variables are determined independently from the loan amount given. However, there *is* a relationship between variables like delinquency, occupation status, etc. and the amount of the loan provided.

As a result, our coefficients may be biased because "loan amount" is already an decision that is accumulated using our independent variables. As such, our exogeneity problem is also a problem of endogeneity.

### Assumption 4: Homoscedasticity
Homoscedacity is the assumption that the errors are consistent over all of the variables. The way to visualize this is to plot the residuals (our errors) against our fitted values (our predictions).

```{r 3.4}
model4_v1  %>%
  plot(1)
```

The plot above reveals that our predictions are generally accurate at lower loan amounts ( less than 30,000) but are increasingly inaccurate at higher loan amounts (greater than than 30,000). The downward slope and negative residuals shows that the model is consistently overpredicting loan amounts at higher loan amounts. This suggests that the model has heteroskedacity.

This heteroskedacity is also worsened by the distribution of the loan_amount variable. The histogram in 1.3 demonstrates how it is skewed significantly towards lower loan amounts. Although this still means the model is overpredicting, we know it is being skewed by the lack of data on higher loan amounts.

Another consideration is that the model is missing a variable that influences higher loan amounts differently than lower amounts. This would be a good avenue to improve future models.

### Assumption 5: Normally Distributed Errors
```{r 3.5}

model4_v1 %>% 
  plot(2)

```
The errors in this Q-Q plot are far from normally distributed: the left tail dips far below the straight line, indicating more extreme negative residuals than expected in a normal distribution. The central portion of the plot is normally distributed, but both ends of the plot show a strong curvature, so the normality assumption is violated. However, this is unsurprising giving the original skewedness of the data- that there were a lot more low loans given out than high loans. Additionally, as noted earlier, there are a lot of loans being taken out at 70000 and 100000 dollars, which can further distort the influence the normal distribution, influencing extreme residuals. To deal with this, potential data cleaning methods previously mentioned such as binning or logarithmic regression of certain variables can be considered.

## Part 4: Influential observations

Since the original data frame is so large, the effect of removing a few outliers would be difficult to detect, which is why working with a sample is appropriate.

Obviously, the results of removing outliers will differ across samples, and the overall effect on the full model would not be identical. However, the value of this part lies in demonstrating how alleviating extreme outliers can improve model performance and stability. We will first plot each test, and then, based on the sample selected for each, examine the impact of outlier removal on the model.

### 4.1: Outliers
```{r 4.1}
# using a sample sample index to avoid overcrowding of visualization

sample_index <- sample(1:nrow(df), 5000)

# finding the residuals for the sample
model4_resid <- rstudent(model4_v1)
model4_resid_sample <- model4_resid[sample_index]

plot(model4_resid_sample)

# what is the most extreme outlier in this sample, which will be eliminated in 4.4
extreme_tupple_in_sample1 <- which.max(abs(model4_resid_sample))
```
The rstudent plot shows that most observations fall close to zero, but there are several points around 2 and -2 and a smaller group near –4, indicating mild to moderate outliers. The most extreme values range from –6 to –8, with the largest reaching just below –8, which oncemore suggests the residual distribution is left-skewed, as we saw in 3.5.

### 4.2 High leverage observations 
``` {r 4.2}

# finding the hat values for the same sample as above
model4_hat <- hatvalues(model4_v1)
model4_hat_sample <- model4_hat[sample_index]

# plotting
plot(model4_hat_sample)

# checking what is the most extreme outlier in this sample 
extreme_tupple_in_sample2 <- which.max(abs(model4_hat_sample))
```
The hat values for this model are extremely low, which means that each tupple individually does not exhert much influence on the model's performance. Most of the hat values are close to 0, which indicates that the majority of observations have vdo not exert much influence on the model. There is a are a few around 0.001, representing moderately leveraged points that are common in large datasets with many predictors. Only a few observations exceed this range, with one point rising above 0.002 as the clear (relative) outlier. Still, in absolute terms these hat terms are very low, which reflects the large sample size.

### 4.3 Influences on the Model 

#### 4.3.1 Cook's Distance
``` {r 4.3.1}

# testing cook's distance 

# finding the cook's distance for the same sample as above
model4_cook <- cooks.distance(model4_v1)
model4_cook_sample <- model4_cook[sample_index]

# plotting
plot(model4_cook_sample)

# checking what is the most extreme outlier in this sample 
extreme_tupple_in_sample3 <- which.max(abs(model4_cook_sample))

```
Cook's distance looks at what would happen to predicted values of the entire model if a data point were removed. For this model, most of Cook’s distance values are extremely close to 0, which means the vast majority of observations have virtually no influence on the fitted model. The points in the range of 0.001–0.003 show somewhat elevated influence, consistent with the presence of stronger outliers as demonstrated in 4.1 and 4.2. The single observation around 0.004 stands out clearly as the most influential point, but even this value is still well below conventional concern thresholds, suggesting that while the model has influential observations, none pose a serious threat to model stability.


#### 4.3.2 DFBETA's
``` {r 4.3.2}
# testing df_beta's

# finding the df_beta's for the same sample as above
model4_beta <- dfbeta(model4_v1)
model4_beta_sample <- model4_beta[sample_index]

# plotting
plot(model4_beta_sample)

# checking what is the most extreme outlier in this sample 
extreme_tupple_in_sample4 <- which.max(abs(model4_beta_sample))
```

DFBETAs measure how much each individual observation changes a specific regression coefficient when it is removed from the model. Most DFBETAs fall between –50 and 50, indicating that nearly all observations have a minimal effect on the model’s individual coefficients. A small number of points fall between 0 and 50, 0 and -50. Only a handful of observations approach ±100, with one exceeding +100 and one falling below –100, making them clear coefficient-level outliers that would influence some coefficients within the model sizeably if they were removed.

### 4.4: What happens to the model when outliers are removed?
``` {r}
df_sample <- df[sample_index, ]
df2 <- df_sample[-c(extreme_tupple_in_sample1, extreme_tupple_in_sample2, extreme_tupple_in_sample3, extreme_tupple_in_sample4), ]

model4_v1_sample <- lm(loan_amount ~ payment_to_income_ratio + annual_income + product_type + years_employed + age + loan_status + defaults_on_file + credit_score + derogatory_marks + delinquencies_last_2yrs + debt_to_income_ratio + interest_rate + occupation_status, data = df_sample)
model4_v1_sample_no_outliers <- lm(loan_amount ~ payment_to_income_ratio + annual_income + product_type + years_employed + age + loan_status + defaults_on_file + credit_score + derogatory_marks + delinquencies_last_2yrs + debt_to_income_ratio + interest_rate + occupation_status, data = df2)

summary(model4_v1_sample)
summary(model4_v1_sample_no_outliers)
```

Removing the most extreme outliers from the sample slightly improved the model, with residual standard error decreasing from 11,390 to 11,320 and R-squared increasing from 0.8111 to 0.8134, indicating a marginally better fit and slightly more explained variance. Standard errors for several coefficients also decreased: payment to income ratio dropped from 1,213 to 1,203, showing that estimates became slightly more precise after removing extreme points. While the effect is noticeable, many moderate outliers remain in the sample, and far more exist in the full dataset. Manually removing outliers is not statistically sound for the full dataset, so alternative approaches like log transformation or binning will be needed to correct for these outliers instead.  

## Conclusion: Model Interpretation

We set out to understand if payment to income ratio, annual income, product type, years employed, age, loan status, defaults on file, credit score, derogatory marks, delinquencies last 2 years, debt to income ratio, loan to income ratio, interest rate, and occupation status, influence the loan amount provided. The ultimate model we chose, Model 4, proved highly significant, with an R-squared of 0.8119, and demonstrated the importance of variables such as loan status and debt-to-income ratio as key predictors of loan amount.

By running multiple regression models and evaluating their BIC, AIC, and MSE scores, we identified Model 4 as the optimal model. However, this model violated every core regression assumption, which substantially undermines its practical utility. Upon reflection, our research question and dataset contain fundamental exogeneity and endogeneity problems that preclude reliable causal inference- which is also visible in part 4, where we look at the influence that outliers cause. We attempted to model loan amount using the very variables that banks themselves use to determine loan amount, creating a circular relationship that rendered meaningful interpretation impossible. While this outcome represents a limitation, it provided valuable insight into the challenges of developing models suitable for real-world application.

Beyond these foundational issues, several concrete improvements could strengthen the analysis. Incorporating additional demographic variables such as education level and gender would provide richer context. Including more granular data on personal circumstances and geography, such as exposure to major life events or regional economic conditions, would capture factors currently absent from our model. Most importantly, longitudinal data tracking individuals over time would provide a more realistic picture of financial trajectories rather than a single snapshot, potentially allowing us to disentangle causal relationships from mere associations.